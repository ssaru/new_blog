---
title: Connect GPU to Minikube
date: 2019-07-25 21:56:53
tags: [Minikube, GPU, Kubernetes]
categories: [Software, Cloud]
keywords:
- kubernetes
- minikube
- gpu
- cloud
coverImage: cover.jpeg
thumbnailImage: cover.jpeg
thumbnailImagePosition: left
autoThumbnailImage: yes
photos: https://images.unsplash.com/photo-1512756290469-ec264b7fbf87?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1549&q=80
---

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ëŠ” Minikubeì—ì„œ GPU ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ í¬ìŠ¤íŒ…í•œë‹¤.

<!-- excerpt -->

<!-- toc -->

# Abstract

í˜„ì¬ ì¿ ë²„ë„¤í‹°ìŠ¤(Kubernetes, ì´í•˜ ì¿ ë²„ë„¤í‹°ìŠ¤)ë¥¼ ì´ìš©í•˜ì—¬ *ë”¥ëŸ¬ë‹ì„ ì§€ì›í•˜ëŠ” ë§ˆì´í¬ë¡œ ì•„í‚¤í…ì³(Micro Architecture, ì´í•˜ ë§ˆì´í¬ë¡œ ì•„í‚¤í…ì³) í”„ë ˆì„ì›Œí¬ ê°œë°œ ë° ì—°êµ¬*ë¥¼ ì§„í–‰ ì¤‘ì´ë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ ê°œë°œ ë° ì—°êµ¬ í”„ë¡œì íŠ¸ì˜ ì›í™œí•œ ì§„í–‰ì„ ìœ„í•´ì„œëŠ” ê°œë°œí•œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ê°œë°œ í™˜ê²½ êµ¬ì¶•ì´ í•„ìš”í•˜ê²Œ ëœë‹¤. í•„ìëŠ” ì´ì „ì— ê°œë°œí•œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ì„œ ì¿ ë²„ë„¤í‹°ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì–´ìˆë˜ í”„ë ˆì„ì›Œí¬ë¥¼ ë¯¸ë‹ˆì¿ ë² (minikube, ì´í•˜ ë¯¸ë‹ˆì¿ ë² )ì—ì„œ êµ¬ë™ì‹œí‚¤ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í–ˆì—ˆë‹¤.

ì´ë²ˆì—ëŠ” GPUê´€ë ¨ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ì„œ **GPU ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ê²Œë” ë¯¸ë‹ˆì¿ ë² ë¥¼ ì„¤ì •í•˜ëŠ” ì‘ì—…**ì„ í–ˆìœ¼ë‚˜ ì •í™•í•˜ì§€ ì•Šì€ ê³µì‹ ë¬¸ì„œì™€ ì¸í„°ë„· ìƒì— ì•ŒíŒŒ, ë² íƒ€ ë²„ì „ë“± íŒŒí¸í™”ëœ ê°€ì´ë“œ ë¬¸ì„œë¡œ ì¸í•´ ë¯¸ë‹ˆì¿ ë² ì—ì„œ GPU ì¸ì‹ì´ ì•ˆë˜ì–´ ì–´ë ¤ì›€ì„ ê²ªì—ˆë‹¤.

ë³¸ í¬ìŠ¤íŒ…ì€ ì•„ë˜ ì„¸ ê°€ì§€ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•´ ì‘ì„±ë˜ì—ˆë‹¤.

1. GPU ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì„ ì§€ì›í•˜ëŠ” ë¯¸ë‹ˆì¿ ë²  ì„¤ì • ë°©ë²• ì†Œê°œ
2. ìˆœì„œ ë³„ë¡œ ì‘ì—… ì‹œ í•´ë‹¹ ì‘ì—…ì´ ì˜ ë˜ì—ˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•
3. ëª‡ ê°€ì§€ ì—ëŸ¬ì™€ í•´ê²° ë°©ë²•

# Introduction

í•„ìëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ *ë”¥ëŸ¬ë‹ì„ ì§€ì›í•˜ëŠ” ë§ˆì´í¬ë¡œ ì•„í‚¤í…ì³ í”„ë ˆì„ì›Œí¬ ê°œë°œì„* í•˜ê³ ìˆìœ¼ë©° ì‚¬ë‚´ì—ì„œëŠ” ì„œë¹„ìŠ¤ í˜¹ì€ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ GPU ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì„ ì§€ì›í•˜ëŠ” ë§ˆì´í¬ë¡œ ì•„í‚¤í…ì³ í”„ë ˆì„ì›Œí¬ê°€ êµ¬ì¶•ë˜ì–´ìˆë‹¤.

ì—¬ëŸ¬ ëª…ì˜ ê°œë°œìì™€ í˜‘ì—…í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰ í•˜ë‹¤ë³´ë©´ ì¼ë°˜ì ìœ¼ë¡œ ë”°ë¥´ëŠ” í”„ë¡œì„¸ìŠ¤ê°€ ìˆë‹¤.

1. ê°œë°œìê°€ ê¸°ëŠ¥ ê°œë°œ ìˆ˜í–‰
2. ê°œë°œ í™˜ê²½ì—ì„œ ê°œë°œëœ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì´ìƒì´ ì—†ìŒì„ í™•ì¸í•œë‹¤
3. ê¸°ëŠ¥ ì‘ë™ ë° í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œ ë˜ë©´ í•´ë‹¹ ê¸°ëŠ¥ì€ í”„ë¡œì íŠ¸ì— ë³‘í•©í•œë‹¤

ì´ ë•Œ, ê°œë°œìì˜ ê°œë°œ í™˜ê²½ í˜¹ì€ í…ŒìŠ¤íŠ¸ í™˜ê²½ì€ ì„œë¹„ìŠ¤ ë°°í¬ í™˜ê²½ê³¼ ìœ ì‚¬í•˜ê²Œë” ì„¤ì •ë˜ì–´ì•¼í•œë‹¤. í•„ìì˜ í”„ë¡œì íŠ¸ê°€ ë”¥ëŸ¬ë‹ì„ ì§€ì›í•˜ëŠ” ë§ˆì´í¬ë¡œ ì•„í‚¤í…ì³ í”„ë ˆì„ì›Œí¬ ê°œë°œì´ê¸° ë•Œë¬¸ì— í•„ìì˜ ê°œë°œ í™˜ê²½ì€ **GPU ì»¨í…Œì´ë„ˆë¥¼ ì§€ì›í•˜ëŠ” ë¯¸ë‹ˆì¿ ë²  í™˜ê²½**ì„ ê°–ì¶°ì•¼ í–ˆë‹¤.

# Related Work

ë¯¸ë‹ˆì¿ ë² ì˜ GPU ì§€ì› ë¬¸ì„œ$^{[1]}$ë¥¼ í™•ì¸í•´ë³´ë©´ ë¯¸ë‹ˆì¿ ë² ê°€ GPUë¥¼ ì§€ì›í•˜ëŠ” ë°©ë²•ì€ í¬ê²Œ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰˜ì–´ì§„ë‹¤.

1. kmv2 ê°€ìƒí™˜ê²½ì„ ì´ìš©í•´ì„œ ì§€ì› (`--vm-driver=kvm2`)
2. í˜¸ìŠ¤íŠ¸ì˜ ìš´ì˜ì²´ì œ í™˜ê²½ì„ ì´ìš©í•´ì„œ ì§€ì› (`--vm-driver=none`)

## kvm2 ê°€ìƒí™˜ê²½(`--vm-driver=kvm2`)

kvm2í™˜ê²½ì—ì„œ GPUì‚¬ìš©ì´ ê°€ëŠ¥í•œ ë¯¸ë‹ˆì¿ ë²  ì„¤ì • ë°©ë²•ì„ ì†Œê°œí•œë‹¤. ì´ ê³¼ì •ì€ ê¸°ì¡´ì— ìš´ì˜ì²´ì œì— ì—°ê²°ë˜ì—ˆë˜ GPU ì¥ì¹˜ë¥¼ kvm2 ê°€ìƒí™˜ê²½ì— ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°(GPU Passthrough)í•˜ëŠ” ì‘ì—…ë“¤ì„ í¬í•¨$^{[2-9]}$í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ê³¼ì •ì´ ë³µì¡í•˜ë‹¤.

í•„ìì˜ ê²½ìš° í•´ë‹¹ ë°©ë²•ì´ ë‘ ê°€ì§€ ì‚¬í•­ì„ ìš”êµ¬í–ˆê¸° ë•Œë¬¸ì— ì„ íƒí•˜ì§€ ì•Šì•˜ë‹¤.

1. ê¸°ì¡´ nvidia ë“œë¼ì´ë²„ì— ì—°ê²°ë˜ì–´ìˆë˜ GPU ì—°ê²° í•´ì œ
2. nvidia ê·¸ë˜í”½ ë“œë¼ì´ë²„ ì‚­ì œ í•„ìš”

í•„ìì˜ ì—…ë¬´ëŠ” ë§ˆì´í¬ë¡œì•„í‚¤í…ì³ í”„ë ˆì„ì›Œí¬ ê°œë°œ ì™¸ì—ë„ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ê°œë°œë„ ìˆë‹¤. kvm2 í™˜ê²½ì—ì„œ ìš”êµ¬í•˜ëŠ” ë‘ ê°€ì§€ ì‚¬í•­ì€ cudaì™€ cudnn ë“± ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ê°œë°œì„ ìœ„í•œ í™˜ê²½ì„¤ì •ì„ ì‘ë™í•˜ì§€ ì•Šë„ë¡ ë§Œë“ ë‹¤.

í•„ìê°€ kvm2í™˜ê²½ì„ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ ì—…ë¬´ ë³„ë¡œ nvidia ê·¸ë˜í”½ ë“œë¼ì´ë²„ ë° ì˜ì¡´ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ì‚­ì œí•˜ëŠ” ì‘ì—…ì„ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼í•œë‹¤. ì´ëŸ° ì´ìœ ë¡œ í•„ìëŠ” kvm2 í™˜ê²½ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ë‹¤.

## í˜¸ìŠ¤íŠ¸ ìš´ì˜ì²´ì œ í™˜ê²½(`--vm-driver=none`)

í•„ìëŠ” ê³µì‹ ë¬¸ì„œë¥¼ ë¯¿ê³  ì´ë¥¼ ë”°ë¼ì„œ ë¯¸ë‹ˆì¿ ë²  ì„¤ì •ì„ ì§„í–‰í•˜ì˜€ë‹¤. ì ìš© ê²°ê³¼ ê¸°ì¡´ì— ì‘ì„±ëœ ë§ˆì´í¬ë¡œ ì•„í‚¤í…ì³  í”„ë ˆì„ì›Œí¬ì—ì„œ **GPUë¥¼ ì‚¬ìš©í•˜ëŠ” íŒŒë“œ(Pods)ê°€ ë¬´í•œ ëŒ€ê¸°(pending)ì— ë¹ ì§€ëŠ” í˜„ìƒ**ì´ ë°œìƒí–ˆë‹¤.

í™•ì¸ ê²°ê³¼ ë¯¸ë‹ˆì¿ ë² ì—ì„œ **GPU ë””ë°”ì´ìŠ¤ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆê±°ë‚˜ GPU ë””ë°”ì´ìŠ¤ëŠ” ì¸ì‹í–ˆìœ¼ë‚˜ ê´€ë ¨ ë“œë¼ì´ë²„ ë° íŒ¨í‚¤ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ì„œ** ì¼ì–´ë‚œ ì¼ì´ì˜€ë‹¤.

ë¯¸ë‹ˆì¿ ë² , ì—”ë¹„ë””ì•„-ë„ì»¤ì˜ ì„¸ë¶€ì‚¬í•­ì„ ëª°ëë˜ í•„ìëŠ” ë°©ëŒ€í•œ êµ¬ê¸€ì„ í—¤ì—„ì¹  ìˆ˜ ë°–ì— ì—†ì—ˆë‹¤$^{[10-17]}$.

# Method

## Prerequisite

ë³¸ í¬ìŠ¤íŒ…ì—ì„œëŠ” ëª‡ê°€ì§€ ì¤€ë¹„ ë˜ì–´ì•¼í•˜ëŠ” ì»´í“¨í„° í™˜ê²½ê³¼ ì‘ì—…ì´ ìˆë‹¤. í•„ìëŠ” ì•„ë˜ì˜ íŒ¨í‚¤ì§€ì™€ Ubuntu 18.04 í™˜ê²½ì—ì„œ ì‘ì—…í•˜ì˜€ë‹¤.

- Docker-CE ( â‰¥ 18.09)

- Nvidia-Docker( â‰¥ 2.03)

- Nvidia GPUë¥¼ ì¥ì‘í•œ ì»´í“¨í„°

- Nvidia ê·¸ë˜í”½ ë“œë¼ì´ë²„ ì„¤ì¹˜

- Minikube(â‰¥ 1.2.0)

<br/>

- Nvidia-Graphics-Driver

        $ nvidia-smi
        Fri Jul 19 21:53:48 2019       
        +-----------------------------------------------------------------------------+
        | NVIDIA-SMI 390.116                Driver Version: 390.116                   |
        |-------------------------------+----------------------+----------------------+
        | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
        | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
        |===============================+======================+======================|
        |   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
        | 33%   30C    P8    24W / 250W |    599MiB / 11175MiB |      1%      Default |
        +-------------------------------+----------------------+----------------------+
        |   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
        | 33%   31C    P8    16W / 250W |      2MiB / 11178MiB |      0%      Default |
        +-------------------------------+----------------------+----------------------+
      
        +-----------------------------------------------------------------------------+
        | Processes:                                                       GPU Memory |
        |  GPU       PID   Type   Process name                             Usage      |
        |=============================================================================|
        |    0      2117      G   /usr/lib/xorg/Xorg                            40MiB |
        |    0      2183      G   /usr/bin/gnome-shell                          50MiB |
        |    0      2975      G   /usr/lib/xorg/Xorg                           334MiB |
        |    0      3116      G   /usr/bin/gnome-shell                         170MiB |
        +-----------------------------------------------------------------------------+

- Docker

        $ docker version
        >>>
        Client:
         Version:           18.09.4
         API version:       1.39
         Go version:        go1.10.8
         Git commit:        d14af54266
         Built:             Wed Mar 27 18:35:44 2019
         OS/Arch:           linux/amd64
         Experimental:      false
      
        Server: Docker Engine - Community
         Engine:
          Version:          18.09.4
          API version:      1.39 (minimum version 1.12)
          Go version:       go1.10.8
          Git commit:       d14af54
          Built:            Wed Mar 27 18:01:48 2019
          OS/Arch:          linux/amd64
          Experimental:     false

- Nvidia-docker

        $ nvidia-docker version
        >>>
        NVIDIA Docker: 2.0.3
      
        ...

## Set docker default-runtime

ë¯¸ë‹ˆì¿ ë² ì—ì„œëŠ” ê¸°ë³¸ ëŸ°íƒ€ì„ì„ Nvidia-Dockerê°€ ì•„ë‹Œ Docker-CEë¡œ ì¸ì‹í•œë‹¤. GPU ì‚¬ìš©ì„ ìœ„í•´ì„œ ë„ì»¤ì˜ ê¸°ë³¸ ëŸ°íƒ€ì„ì„ Nvidia-Dockerë¡œ ë³€ê²½í•´ì¤€ë‹¤.

`/etc/docker/daemon.json` íŒŒì¼ì—ì„œ `default-runtime`ì„ `nvidia`ë¡œ ë³€ê²½í•œë‹¤.

    {
        "default-runtime": "nvidia",
    
        "runtimes": {
            "nvidia": {
                "path": "nvidia-container-runtime",
                "runtimeArgs": []
            }
        }
    }

ë³€ê²½ì´ ë‹¤ ë˜ì—ˆë‹¤ë©´,  ë„ì»¤ë¥¼ ì¬ì‹œì‘í•œë‹¤.

    $ sudo service docker restart

## Minikube start

ë¯¸ë‹ˆì¿ ë² ë¥¼ ì‹¤í–‰í•œë‹¤. í•„ìš”í•œ ì˜µì…˜ì— ëŒ€í•´ì„œëŠ” í‘œì— ì„¤ëª…í•´ ë‘ì—ˆë‹¤.

    $ sudo -E minikube start --vm-driver=none --apiserver-ips 127.0.0.1 --apiserver-name localhost --docker-opt default-runtime=nvidia --feature-gates=DevicePlugins=true --kubernetes-version v1.15.0
    >>>
    ğŸŸŸ  minikube v1.2.0 on linux (amd64)
    ğŸŸŸ  Creating none VM (CPUs=2, Memory=2048MB, Disk=20000MB) ...
    ğŸŸŸ  Configuring environment for Kubernetes v1.15.0 on Docker 18.09.4
        â–ª opt default-runtime=nvidia
        â–ª kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
    ğŸŸŸ  Downloading kubeadm v1.15.0
    ğŸŸŸ  Downloading kubelet v1.15.0
    ğŸŸŸ  Pulling images ...
    ğŸŸŸ  Launching Kubernetes ... 
    ğŸŸŸ  Configuring local host environment ...
    
    âš ï¸  The 'none' driver provides limited isolation and may reduce system security and reliability.
    âš ï¸  For more information, see:
    ğŸŸŸ  https://github.com/kubernetes/minikube/blob/master/docs/vmdriver-none.md
    
    âŒ›  Verifying: apiserver proxy etcd scheduler controller dns
    ğŸŸŸ  Done! kubectl is now configured to use "minikube"

| name                                | description                                                                               |
| ----------------------------------- | ----------------------------------------------------------------------------------------- |
| --docker-opt default-runtime=nvidia | ë¯¸ë‹ˆì¿ ë² ì˜ ê¸°ë³¸ ë„ì»¤ë¥¼ ì—”ë¹„ë””ì•„ ë„ì»¤ë¡œ ì„¤ì •í•œë‹¤                                                                |
| --feature-gates=DevicePlugins=true  | GPU ì§€ì›ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ì•Œë°”/ë² íƒ€ ë‹¨ê³„ì— ì†í•œë‹¤. ë”°ë¼ì„œ ì´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” feature-gates ì˜µì…˜ì„ ì´ìš©í•´ì„œ GPU ì‚¬ìš© ì˜µì…˜ì„ ë³€ê²½í•´ì¤˜ì•¼í•œë‹¤ |
| --kubernetes-version v1.15.0        | NVIDIA ë“œë¼ì´ë²„ë¥¼ ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ ì—°ê²°í•´ì£¼ëŠ” k8s-device-plugin$^{[18]}$ì€ 1.10ì´ìƒì˜ ì¿ ë²„ë„¤í‹°ìŠ¤ ë²„ì „ì„ ìš”êµ¬í•œë‹¤              |

ë¯¸ë‹ˆì¿ ë²  ì‘ë™ì„ í™•ì¸í•œë‹¤.

    $ kubectl get pods --all-namespaces
    
    NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE
    kube-system   coredns-5c98db65d4-nks96               1/1     Running   0          149m
    kube-system   coredns-5c98db65d4-ns9dr               1/1     Running   0          149m
    kube-system   etcd-minikube                          1/1     Running   0          148m
    kube-system   kube-addon-manager-minikube            1/1     Running   0          148m
    kube-system   kube-apiserver-minikube                1/1     Running   0          148m
    kube-system   kube-controller-manager-minikube       1/1     Running   0          148m
    kube-system   kube-proxy-wdhfd                       1/1     Running   0          149m
    kube-system   kube-scheduler-minikube                1/1     Running   0          148m
    kube-system   storage-provisioner                    1/1     Running   0          149m

<br>

**CrashLoopBackOff Error**

ë§Œì•½ kube-systemì˜ corednsì—ì„œ CrashLoopBackOff Errorê°€ ë°œìƒí•œë‹¤ë©´, coredns ì„¤ì •ì—ì„œ Corefileì•ˆì˜ loopë¥¼ ì‚­ì œí•œë‹¤.

    $ kubectl -n kube-system edit configmap coredns
    >>>
    # Please edit the object below. Lines beginning with a '#' will be ignored,
    # and an empty file will abort the edit. If an error occurs while saving this file will be
    # reopened with the relevant failures.
    #
    apiVersion: v1
    data:
      Corefile: |
        .:53 {
            errors
            health
            kubernetes cluster.local in-addr.arpa ip6.arpa {
               pods insecure
               upstream
               fallthrough in-addr.arpa ip6.arpa
               ttl 30
            }
            prometheus :9153
            forward . /etc/resolv.conf
            cache 30
            loop -> remove this line
            reload
            loadbalance
        }
    kind: ConfigMap
    metadata:
      creationTimestamp: "2019-07-19T10:34:27Z"
      name: coredns
      namespace: kube-system
      resourceVersion: "189"
      selfLink: /api/v1/namespaces/kube-system/configmaps/coredns
      uid: 8aa1d75a-0986-457f-81d6-d0339308a98a

ì´ì œ ê¸°ì¡´ì˜ í¬ë“œ(Pods)ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œìš´ ì„¤ì •ì´ ì ìš©ëœ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤.

    $ kubectl -n kube-system delete pod -l k8s-app=kube-dns

<br>

**Check GPU status**

ë¯¸ë‹ˆì¿ ë² ì˜ GPU ë§ˆìš´íŠ¸ ìƒíƒœë¥¼ í™•ì¸í•œë‹¤. ì§€ê¸ˆì€ GPUê°€ `<none>`ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ê°€ ìˆë‹¤.

    $ kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
    >>>
    NAME       GPU
    minikube   <none>

## k8s-device-plugin

k8s-device-plugin$^{[18]}$ì„ ë¯¸ë‹ˆì¿ ë² ì— ì ìš©í•œë‹¤. k8s-device-pluginì€ ë¯¸ë‹ˆì¿ ë² ì—ì„œ GPU ë””ë°”ì´ìŠ¤ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤.

    $ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta/nvidia-device-plugin.yml
    $ kubectl get pods --all-namespaces
    >>>
    NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE
    ...
    kube-system   nvidia-device-plugin-daemonset-4xlfc   1/1     Running   0          146m
    ...

k8s-device-pluginì´ Runningìƒíƒœë¡œ ë°”ë€Œì˜€ë‹¤ë©´, GPU ìƒíƒœë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ë³¸ë‹¤. GPUì˜ ê°œìˆ˜ê°€ 2ê°œë¡œ ë³€ê²½ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

    $ kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
    >>>
    NAME       GPU
    minikube   2

## GPU-demo.yaml

GPU ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•  yamlíŒŒì¼ì„ ìƒì„±í•œë‹¤. ì´ëŠ” ì‹¤ì œë¡œ ì»¨í…Œì´ë„ˆê°€ ë¯¸ë‹ˆì¿ ë² ì—ì„œ ì‹¤í–‰ë˜ì—ˆì„ ë•Œ, ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•¨ì´ë‹¤.

**GPU-demo.yaml**

    apiVersion: v1
    kind: Pod
    metadata:
      name: gpu
    spec:
    
      containers:
      - name: gpu-container
        image: nvidia/cuda:9.0-runtime
        command:
          - "/bin/sh"
          - "-c"
        args:
          - nvidia-smi && tail -f /dev/null
    
        resources:
          requests:
            nvidia.com/gpu: 2
          limits:
            nvidia.com/gpu: 2

 ë¯¸ë‹ˆì¿ ë² ì— ì»¨í…Œì´ë„ˆë¥¼ ë„ì›Œë³´ì.

    $ kubectl apply -f GPU-demo.yaml
    >>>
    pod/gpu created
    
    $ kubectl get pods -n default
    >>>
    NAME   READY   STATUS    RESTARTS   AGE
    gpu    1/1     Running   0          157m
    
    $ kubectl logs gpu
    >>>
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 390.116                Driver Version: 390.116                   |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |===============================+======================+======================|
    |   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
    | 33%   30C    P8    24W / 250W |    599MiB / 11175MiB |      1%      Default |
    +-------------------------------+----------------------+----------------------+
    |   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
    | 33%   31C    P8    16W / 250W |      2MiB / 11178MiB |      0%      Default |
    +-------------------------------+----------------------+----------------------+
    
    +-----------------------------------------------------------------------------+
    | Processes:                                                       GPU Memory |
    |  GPU       PID   Type   Process name                             Usage      |
    |=============================================================================|
    |    0      2117      G   /usr/lib/xorg/Xorg                            40MiB |
    |    0      2183      G   /usr/bin/gnome-shell                          50MiB |
    |    0      2975      G   /usr/lib/xorg/Xorg                           334MiB |
    |    0      3116      G   /usr/bin/gnome-shell                         170MiB |
    +-----------------------------------------------------------------------------+

### Access container

ì¡°ê¸ˆ ë” í™•ì‹¤í•˜ê²Œ í•˜ê¸° ìœ„í•´ì„œ ë¯¸ë‹ˆì¿ ë² ì— ë°°í¬í•œ ì»¨í…Œì´ë„ˆì— ì ‘ì†í•´ë³´ì. ì ‘ì† í•œ í›„ì—ëŠ” `nvidia-smi`ì™€ `nvcc -V`ëª…ë ¹ì–´ë¡œ GPUê°€ ì˜ ì—°ê²°ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•œë‹¤.

    $ kubectl exec gpu -it g -- /bin/bash
    >>>
        root@gpu:/# nvcc -V
        >>>
        nvcc: NVIDIA (R) Cuda compiler driver
        Copyright (c) 2005-2017 NVIDIA Corporation
        Built on Fri_Sep__1_21:08:03_CDT_2017
        Cuda compilation tools, release 9.0, V9.0.176
    
        root@gpu:/# nvidia-smi
        +-----------------------------------------------------------------------------+
        | NVIDIA-SMI 390.116                Driver Version: 390.116                   |
        |-------------------------------+----------------------+----------------------+
        | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
        | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
        |===============================+======================+======================|
        |   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
        | 33%   30C    P8    24W / 250W |    599MiB / 11175MiB |      1%      Default |
        +-------------------------------+----------------------+----------------------+
        |   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
        | 33%   31C    P8    16W / 250W |      2MiB / 11178MiB |      0%      Default |
        +-------------------------------+----------------------+----------------------+
    
        +-----------------------------------------------------------------------------+
        | Processes:                                                       GPU Memory |
        |  GPU       PID   Type   Process name                             Usage      |
        |=============================================================================|
        |    0      2117      G   /usr/lib/xorg/Xorg                            40MiB |
        |    0      2183      G   /usr/bin/gnome-shell                          50MiB |
        |    0      2975      G   /usr/lib/xorg/Xorg                           334MiB |
        |    0      3116      G   /usr/bin/gnome-shell                         170MiB |
        +-----------------------------------------------------------------------------+

## Tip of Testing & Debugging

### Helpful command

í•„ìëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ì™€ ë„ì»¤í™˜ê²½ì´ ìµìˆ™í•˜ì§€ ì•Šì•„ì„œ ìƒê°ë³´ë‹¤ ë§ì´ í—¤ë§¸ëŠ”ë°, ë§¤ ìŠ¤í… ìŠ¤í… ì‘ì—…í•  ë•Œë§ˆë‹¤ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ `kubectl describe`, `kubectl logs`, `minikube logs` `lspci -nn | grep -i nvidia` ë¥¼ ì—´ì‹¬íˆ ì‚¬ìš©í•´ì„œ ë””ë²„ê¹…ì„ ì§„í–‰í•˜ì˜€ë‹¤.

- `kubectl describe`, `kubectl logs`ëŠ” ë¯¸ë‹ˆì¿ ë² ì˜ íŒŒë“œ(Pods)ì˜ ìƒíƒœ ë° ë¡œê·¸ ë©”ì„¸ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤
- `minikube logs`ëŠ” ë¯¸ë‹ˆì¿ ë²  ìì²´ì˜ ë¡œê·¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤
- `lspci -nn | grep -i nvidia`ëŠ” ì—°ê²°ë˜ì–´ìˆëŠ” ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì»¨í…Œì´ë„ˆì—ì„œ ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œëŠ” ë³„ë„ì˜ Dockerfileì„ ì‘ì„±í•´ì„œ lspci utilì„ ì„¤ì¹˜í•´ì•¼ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤

### Configuration file clearning

ë¯¸ë‹ˆì¿ ë² ë¡œ ì‘ì—…ì„ í•˜ë‹¤ê°€ ì˜ëª»ë˜ì–´ì„œ í˜¹ì€ ì¬í˜„ì„ ìœ„í•´ì„œ ì¬ì„¤ì¹˜ë¥¼ í•˜ëŠ” ê²½ìš°ê°€ ì¢…ì¢… ìˆë‹¤. ì´ ë•Œ ê¸°ì¡´ì˜ ì„¤ì • íŒŒì¼ ì‚­ì œë¥¼ í•´ì¤˜ì•¼í•œë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì´ì „ì— ì„¤ì •ë“¤ì´ ê°™ì´ ë”°ë¼ì™€ì„œ ì´ì „ ì‘ì—…ì—ì„œ ë°œìƒí•œ ì—ëŸ¬ê°€ ê·¸ëŒ€ë¡œ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ ì•„ë˜ íŒŒì¼ë“¤ì„ ì‚­ì œí–ˆëŠ”ì§€ ê¼­ í™•ì¸í•˜ì.

- `~/.kube`
- `~/.minikube`
- `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf`

# Reference

1. [(Experimental) NVIDIA GPU support in minikube](https://github.com/kubernetes/minikube/blob/master/docs/gpu.md)
2. [How to enable IOMMU on Ubuntu 18.04](https://www.reddit.com/r/linuxquestions/comments/bgbpim/how_to_enable_iommu_on_ubuntu_1804/)
3. [Ubuntu 18.04 - KVM/QEMU Windows 10 GPU Passthrough](https://blog.zerosector.io/2018/07/28/kvm-qemu-windows-10-gpu-passthrough/)
4. [\[GUIDE\] Linux PCI GPU VFIO Passthrough](https://linustechtips.com/main/topic/978579-guide-linux-pci-gpu-vfio-passthrough/)
5. [Testing VFIO with GPU](https://github.com/intel/nemu/wiki/Testing-VFIO-with-GPU)
6. [KVM: GPU Passthrough](https://www.server-world.info/en/note?os=Ubuntu_18.04&p=kvm&f=11)
7. [KVM ê¸°ë°˜ì˜ GPU Passthrough í™˜ê²½](https://www.nepirity.com/blog/kvm-gpu-passthrough/)
8. [USERSPACE I/Oì™€ VFIO](https://smallake.kr/?p=9712)
9. [Passthrough](http://iusethis.keizie.net/collection/virtualization/passthrough)
10. [0/1 nodes are available: 1 Insufficient nvidia.com/gpu](https://github.com/NVIDIA/k8s-device-plugin/issues/33)
11. [minikube - GPU support](https://github.com/kubernetes/minikube/issues/2115https://github.com/kubernetes/minikube/issues/2115)
12. [Kubeflow - Troubleshooting](https://www.kubeflow.org/docs/other-guides/troubleshooting/)
13. [Running TensorFlow Kubernetes](https://medium.com/jim-fleming/running-tensorflow-on-kubernetes-ca00d0e67539)
14. [Kubernetes - Schedule GPUs](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)
15. [Kubernetes - Feature Gates](https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/)
16. [Kubeflow Setup](https://nvaitc.github.io/workstation-setup-guide/kubeflow-setup.html)
17. [Kubernetesì—ì„œ gpu pod ìƒì„±](https://likefree.tistory.com/15)
18. [NVIDIA device plugin for Kubernetes](https://github.com/NVIDIA/k8s-device-plugin)

# Thanks to

## ê²€ìˆ˜ì

- [ë¬¸ë™ìš±](https://evan-moon.github.io/)
- [ì •ë¯¸ì—°](https://lovablebaby1015.wordpress.com/)
- [ê¹€ìˆ˜ì •](https://github.com/soodevv)
- [ê¹€ë³´ì„­](https://aisolab.github.io/)
